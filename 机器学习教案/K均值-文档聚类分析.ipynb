{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设有一个博客平台，用户在平台上发布博客，我们对博客进行聚类分析，以方便展示不同类别下的热门文章"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading documents ...\n",
      "summary: 3949 documents in 4 categories.\n",
      "done in 3.5900049209594727 seconds\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from sklearn.datasets import load_files\n",
    "\n",
    "print(\"loading documents ...\")\n",
    "t = time()\n",
    "docs = load_files('datasets/clustering/data')\n",
    "print(\"summary: {0} documents in {1} categories.\".format(\n",
    "    len(docs.data), len(docs.target_names)))\n",
    "print(\"done in {0} seconds\".format(time() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorizing documents ...\n",
      "n_samples: 3949, n_features: 20000\n",
      "number of non-zero features in sample [datasets/clustering/data\\sci.electronics\\11902-54322]: 56\n",
      "done in 3.9820303916931152 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "max_features = 20000\n",
    "print(\"vectorizing documents ...\")\n",
    "t = time()\n",
    "vectorizer = TfidfVectorizer(max_df=0.4, \n",
    "                             min_df=2, \n",
    "                             max_features=max_features, \n",
    "                             encoding='latin-1')\n",
    "X = vectorizer.fit_transform((d for d in docs.data))\n",
    "print(\"n_samples: %d, n_features: %d\" % X.shape)\n",
    "print(\"number of non-zero features in sample [{0}]: {1}\".format(\n",
    "    docs.filenames[0], X[0].getnnz()))\n",
    "print(\"done in {0} seconds\".format(time() - t))\n",
    "\n",
    "#函数参数 https://blog.csdn.net/laobai1015/article/details/80451371\n",
    " #min_df，当设置为浮点数时，过滤出现在超过max_df/低于min_df比例的句子中的词语；正整数时,则是超过max_df句句子。\n",
    "    #max_features，仅考虑max_features--按语料词频排序"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max_df = 0.4表示如果一个单词在40%的文档里都出现过，则认为这是一个高频词，对文档聚类没有帮助，在生成词典时就会剔除这个词    \n",
    "Min_df=2表示，如果一个单词的词频太低，只在两个以下（包含两个）的文档里出现，则也把这个单词从词典里剔除    \n",
    "maxfeatures可以进一步过滤词典的大小，它会根据TF-IDF权重从高到低进行排序，然后取前面权重高的单词构成词典   \n",
    "   \n",
    "   \n",
    "TfidfVectorizer 类是用来把所有的文档转换为矩阵，矩阵每行都代表一个文档，一行中每个元素代表一个对应词语的重要性，词语重要性用 TF-IDF 来表示\n",
    "○其中fit_transform () 方法是fit()和 transform() 合并起来\n",
    "○其中 ,fit () 会先完成语料库分析、 提取词典等操作\n",
    "○transform() 把对每篇文档转换为向量，最终构成矩阵，保存在变量里 \n",
    "   \n",
    "\n",
    "从输出可知，我们的一篇文章构成的向量是一个稀疏向量，其大部分元素都为0     \n",
    "这也容易理解，我们的词典大小为20000个，而示例文章中不重复的单词却只有56个  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clustering documents ...\n",
      "Initialization complete\n",
      "Iteration  0, inertia 7502.026\n",
      "Iteration  1, inertia 3844.598\n",
      "Iteration  2, inertia 3832.021\n",
      "Iteration  3, inertia 3828.654\n",
      "Iteration  4, inertia 3827.405\n",
      "Iteration  5, inertia 3826.808\n",
      "Iteration  6, inertia 3826.471\n",
      "Iteration  7, inertia 3826.302\n",
      "Iteration  8, inertia 3826.195\n",
      "Iteration  9, inertia 3826.019\n",
      "Iteration 10, inertia 3825.825\n",
      "Iteration 11, inertia 3825.739\n",
      "Iteration 12, inertia 3825.628\n",
      "Iteration 13, inertia 3825.543\n",
      "Iteration 14, inertia 3825.510\n",
      "Iteration 15, inertia 3825.465\n",
      "Iteration 16, inertia 3825.449\n",
      "Iteration 17, inertia 3825.441\n",
      "Iteration 18, inertia 3825.440\n",
      "Iteration 19, inertia 3825.438\n",
      "Iteration 20, inertia 3825.432\n",
      "Iteration 21, inertia 3825.431\n",
      "Iteration 22, inertia 3825.429\n",
      "Iteration 23, inertia 3825.428\n",
      "Iteration 24, inertia 3825.426\n",
      "Iteration 25, inertia 3825.421\n",
      "Iteration 26, inertia 3825.416\n",
      "Converged at iteration 26: center shift 0.000000e+00 within tolerance 4.896692e-07\n",
      "Initialization complete\n",
      "Iteration  0, inertia 7413.919\n",
      "Iteration  1, inertia 3849.266\n",
      "Iteration  2, inertia 3841.036\n",
      "Iteration  3, inertia 3836.077\n",
      "Iteration  4, inertia 3832.397\n",
      "Iteration  5, inertia 3829.357\n",
      "Iteration  6, inertia 3827.284\n",
      "Iteration  7, inertia 3825.297\n",
      "Iteration  8, inertia 3823.001\n",
      "Iteration  9, inertia 3820.092\n",
      "Iteration 10, inertia 3818.666\n",
      "Iteration 11, inertia 3818.059\n",
      "Iteration 12, inertia 3817.831\n",
      "Iteration 13, inertia 3817.763\n",
      "Iteration 14, inertia 3817.730\n",
      "Iteration 15, inertia 3817.701\n",
      "Iteration 16, inertia 3817.680\n",
      "Iteration 17, inertia 3817.674\n",
      "Iteration 18, inertia 3817.666\n",
      "Iteration 19, inertia 3817.657\n",
      "Iteration 20, inertia 3817.647\n",
      "Iteration 21, inertia 3817.643\n",
      "Iteration 22, inertia 3817.640\n",
      "Iteration 23, inertia 3817.636\n",
      "Iteration 24, inertia 3817.634\n",
      "Converged at iteration 24: center shift 0.000000e+00 within tolerance 4.896692e-07\n",
      "Initialization complete\n",
      "Iteration  0, inertia 7542.393\n",
      "Iteration  1, inertia 3848.971\n",
      "Iteration  2, inertia 3840.779\n",
      "Iteration  3, inertia 3835.321\n",
      "Iteration  4, inertia 3832.696\n",
      "Iteration  5, inertia 3830.586\n",
      "Iteration  6, inertia 3828.901\n",
      "Iteration  7, inertia 3827.184\n",
      "Iteration  8, inertia 3825.225\n",
      "Iteration  9, inertia 3822.626\n",
      "Iteration 10, inertia 3821.824\n",
      "Iteration 11, inertia 3821.438\n",
      "Iteration 12, inertia 3821.160\n",
      "Iteration 13, inertia 3820.954\n",
      "Iteration 14, inertia 3820.776\n",
      "Iteration 15, inertia 3820.663\n",
      "Iteration 16, inertia 3820.598\n",
      "Iteration 17, inertia 3820.524\n",
      "Iteration 18, inertia 3820.442\n",
      "Iteration 19, inertia 3820.355\n",
      "Iteration 20, inertia 3820.236\n",
      "Iteration 21, inertia 3820.123\n",
      "Iteration 22, inertia 3819.954\n",
      "Iteration 23, inertia 3819.751\n",
      "Iteration 24, inertia 3819.575\n",
      "Iteration 25, inertia 3819.301\n",
      "Iteration 26, inertia 3819.066\n",
      "Iteration 27, inertia 3818.861\n",
      "Iteration 28, inertia 3818.668\n",
      "Iteration 29, inertia 3818.462\n",
      "Iteration 30, inertia 3818.253\n",
      "Iteration 31, inertia 3818.103\n",
      "Iteration 32, inertia 3817.975\n",
      "Iteration 33, inertia 3817.904\n",
      "Iteration 34, inertia 3817.863\n",
      "Iteration 35, inertia 3817.837\n",
      "Iteration 36, inertia 3817.811\n",
      "Iteration 37, inertia 3817.787\n",
      "Iteration 38, inertia 3817.765\n",
      "Iteration 39, inertia 3817.747\n",
      "Iteration 40, inertia 3817.736\n",
      "Iteration 41, inertia 3817.724\n",
      "Iteration 42, inertia 3817.713\n",
      "Iteration 43, inertia 3817.701\n",
      "Iteration 44, inertia 3817.694\n",
      "Iteration 45, inertia 3817.682\n",
      "Iteration 46, inertia 3817.670\n",
      "Iteration 47, inertia 3817.640\n",
      "Iteration 48, inertia 3817.626\n",
      "Iteration 49, inertia 3817.610\n",
      "Iteration 50, inertia 3817.587\n",
      "Iteration 51, inertia 3817.566\n",
      "Iteration 52, inertia 3817.549\n",
      "Iteration 53, inertia 3817.541\n",
      "Iteration 54, inertia 3817.539\n",
      "Iteration 55, inertia 3817.537\n",
      "Converged at iteration 55: center shift 0.000000e+00 within tolerance 4.896692e-07\n",
      "kmean: k=4, cost=3817\n",
      "done in 55.66559386253357 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "print(\"clustering documents ...\")\n",
    "t = time()\n",
    "n_clusters = 4\n",
    "kmean = KMeans(n_clusters=n_clusters, \n",
    "               max_iter=100,\n",
    "               tol=0.01,\n",
    "               verbose=1,\n",
    "               n_init=3)\n",
    "kmean.fit(X);\n",
    "print(\"kmean: k={}, cost={}\".format(n_clusters, int(kmean.inertia_)))\n",
    "print(\"done in {0} seconds\".format(time() - t))\n",
    "#n_init设为3意味着进行3次随机初始化，选择效果最好的一种来作为模型 https://blog.csdn.net/EleanorWiser/article/details/70226704"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "聚类个数为4个  \n",
    "Max_iter=I00表示最多进行100次k－均值法代   \n",
    "tol=0.1表示中心点移动距离小于0.1时就认为算法已经收敛,停止迭代   \n",
    "verbose=I表示输出法代的过程信息    \n",
    "n_init=3表示进行3次随机初始化，选择效果最好的一种作为模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3949"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(kmean.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总共进行了3次k－均值聚类分析，分别做了26 55 24次法代后收敛。这样就把3949个文档进行自动分类   \n",
    "kmean.labes里保存的就是这些文档的类别信息  \n",
    "如我们所预料，len(kmean.labes）的值是3949，还可以查看1000～1010这10个文档的聚类情况及其对应的文件名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 1, 3, 1, 3, 2, 1, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmean.labels_[1000:1010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['datasets/clustering/data\\\\sci.crypt\\\\10888-15289',\n",
       "       'datasets/clustering/data\\\\sci.crypt\\\\11490-15880',\n",
       "       'datasets/clustering/data\\\\sci.crypt\\\\11270-15346',\n",
       "       'datasets/clustering/data\\\\sci.electronics\\\\12383-53525',\n",
       "       'datasets/clustering/data\\\\sci.space\\\\13826-60862',\n",
       "       'datasets/clustering/data\\\\sci.electronics\\\\11631-54106',\n",
       "       'datasets/clustering/data\\\\sci.space\\\\14235-61437',\n",
       "       'datasets/clustering/data\\\\sci.crypt\\\\11508-15928',\n",
       "       'datasets/clustering/data\\\\sci.space\\\\13593-60824',\n",
       "       'datasets/clustering/data\\\\sci.electronics\\\\12304-52801'],\n",
       "      dtype='<U52')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs.filenames[1000:1010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 20000)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmean.cluster_centers_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 2, 0], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#函数补充\n",
    "a = np.array([10,30,20,40])\n",
    "a.argsort() #返回升序索引\n",
    "b = a.argsort()[::-1] #返回降序索引\n",
    "#t1 = vectorizer.get_feature_names()\n",
    "#t1[2]\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e =  b[0:2]\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[12313, 16356, 12398, ...,  6878,  6877, 19999],\n",
       "       [ 2337, 12398, 10635, ...,  7362,  7363,  8367],\n",
       "       [10522,  4415,  6936, ...,  8539, 16223, 19999],\n",
       "       [16848,  8962, 12463, ..., 14902,  7521, 19999]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#查看每种类别文档中，其权限最高的10个单词\n",
    "from __future__ import print_function\n",
    "\n",
    "print(\"Top terms per cluster:\")\n",
    "\n",
    "order_centroids = kmean.cluster_centers_.argsort()[:, ::-1] #返回降序索引\n",
    "#order_centroids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12313, 16356, 12398, 13888,  8480,  8263,  2907,  8971,  8877,  8831], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " order_centroids[0, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'msg'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms = vectorizer.get_feature_names()#得到词典单词列表\n",
    "terms[12313]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: msg she my pitt gordon geb banks her he has\n",
      "Cluster 1: any my know by me your like anyone will do\n",
      "Cluster 2: key clipper encryption chip government will keys escrow we nsa\n",
      "Cluster 3: space henry nasa toronto shuttle zoo pat moon spencer orbit\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(n_clusters):\n",
    "    print(\"Cluster %d:\" % i, end='')\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind], end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OVER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考：#https://blog.csdn.net/sinat_26917383/article/details/70577710     \n",
    "\n",
    "1、homogeneity_score： 同质性homogeneity       \n",
    "2、completeness_score： 完整性completeness\n",
    "3、v_measure_score： 两者的调和平均，为1最好    \n",
    "4、adjusted_rand_score：兰德指数，数值越大表示与真实情况越吻合[-1,1]\n",
    "5、silhouette_score：轮廓系数：同类别样本越近不同类别越远分数越高[-1,1],不需要已标记数据集的前提下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity: 0.453\n",
      "Completeness: 0.532\n",
      "V-measure: 0.489\n",
      "Adjusted Rand-Index: 0.295\n",
      "Silhouette Coefficient: 0.004\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "labels = docs.target\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels, kmean.labels_))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(labels, kmean.labels_))\n",
    "print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels, kmean.labels_))\n",
    "print(\"Adjusted Rand-Index: %.3f\"\n",
    "      % metrics.adjusted_rand_score(labels, kmean.labels_))\n",
    "print(\"Silhouette Coefficient: %0.3f\"\n",
    "      % metrics.silhouette_score(X, kmean.labels_, sample_size=1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这些数值是好是坏呢？坦白讲，只能算为一般。可以结合上述介绍的指标的含义，理解这些数值背后表达的意义,可能的一个原因是数据集质量不高，感兴趣的同学可以阅读原始的语料库，检验一下如果通过人工标记，是否能够标记出这些文章的正确分类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 2, 0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([10, 30, 20, 40])\n",
    "a.argsort()[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 2, 0, 1],\n",
       "       [3, 1, 2, 0],\n",
       "       [1, 2, 3, 0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[20, 10, 30, 40], [100, 300, 200, 400], [1, 5, 3, 2]])\n",
    "a.argsort()[:, ::-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
